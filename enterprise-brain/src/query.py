import os
import argparse
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv

# åŠ è½½ .env
load_dotenv()

# é…ç½®è·¯å¾„
DB_DIR = "chroma_db"

def query_brain(question: str):
    # 1. åˆå§‹åŒ– Embedding æ¨¡å‹ (å¿…é¡»ä¸ ingest æ—¶ä¸€è‡´)
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

    # 2. åŠ è½½å‘é‡æ•°æ®åº“
    vector_store = Chroma(
        persist_directory=DB_DIR,
        embedding_function=embeddings
    )

    # 3. æ£€ç´¢ (Retrieval)
    print(f"ğŸ” Searching brain for: '{question}'...")
    # k=3 è¡¨ç¤ºæ‰¾ 3 ä¸ªæœ€ç›¸å…³çš„ç‰‡æ®µ
    results = vector_store.similarity_search(question, k=3)
    
    if not results:
        print("âŒ No relevant information found in the brain.")
        return

    # å°†æ£€ç´¢åˆ°çš„ç‰‡æ®µæ‹¼æ¥æˆ Context
    context_text = "\n\n---\n\n".join([doc.page_content for doc in results])
    
    # 4. æ„å»º Prompt (RAG æ ¸å¿ƒ)
    # å¼ºåˆ¶ AI æ‰®æ¼”ä¸“å®¶è§’è‰²ï¼Œå¹¶åªä¾æ® Context å›ç­”
    prompt_template = ChatPromptTemplate.from_template("""
    ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ AI æˆ˜ç•¥é¡¾é—®ã€‚è¯·åŸºäºä»¥ä¸‹çš„ã€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‘ï¼Œå›ç­”ç”¨æˆ·çš„ã€é—®é¢˜ã€‘ã€‚
    
    è§„åˆ™ï¼š
    1. å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç­”æ¡ˆï¼Œè¯·ç›´æ¥è¯´â€œæˆ‘çš„çŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯â€ï¼Œä¸è¦ç¼–é€ ã€‚
    2. å›ç­”è¦ä¸“ä¸šã€ç®€æ´ï¼Œåƒå·¥ç¨‹å¸ˆå¯¹å·¥ç¨‹å¸ˆè¯´è¯ã€‚
    3. å¼•ç”¨ä¸Šä¸‹æ–‡ä¸­çš„å…³é”®æ•°æ®æˆ–è§‚ç‚¹æ¥æ”¯æŒä½ çš„å›ç­”ã€‚

    ã€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‘ï¼š
    {context}

    ã€é—®é¢˜ã€‘ï¼š
    {question}
    """)

    # 5. è°ƒç”¨ LLM (DeepSeek)
    llm = ChatOpenAI(
        model=os.getenv("LLM_MODEL_NAME", "deepseek-chat"),
        api_key=os.getenv("DEEPSEEK_API_KEY"),
        base_url=os.getenv("DEEPSEEK_BASE_URL"),
        temperature=0.1  # ä½æ¸©æ¨¡å¼ï¼Œç¡®ä¿å‡†ç¡®æ€§
    )

    # 6. ç”Ÿæˆå›ç­”
    chain = prompt_template | llm
    print("ğŸ¤– Thinking...")
    response = chain.invoke({"context": context_text, "question": question})

    print("\n" + "="*50)
    print(f"ğŸ’¡ Answer:\n{response.content}")
    print("="*50 + "\n")
    
    # è°ƒè¯•ï¼šæ˜¾ç¤ºå¼•ç”¨æ¥æº
    print("ğŸ“š Sources used:")
    for doc in results:
        source = doc.metadata.get('source', 'Unknown')
        print(f" - {source}")

if __name__ == "__main__":
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="Ask the Enterprise Brain")
    parser.add_argument("question", type=str, nargs="?", help="The question to ask", default="What is the strategy for Week 1?")
    args = parser.parse_args()
    
    query_brain(args.question)
