import os
import glob
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from dotenv import load_dotenv

# åŠ è½½ .env
load_dotenv()

# é…ç½®è·¯å¾„
DATA_DIR = "data"
DB_DIR = "chroma_db"

import chromadb

def ingest_docs():
    print(f"ğŸ“‚ Loading documents from {DATA_DIR}...")
    
    # ... åŸæœ‰åŠ è½½é€»è¾‘ä¸å˜ ...

    # 3. åˆå§‹åŒ– Embedding æ¨¡å‹
    print("ğŸ§  Initializing embedding model (HuggingFace)...")
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

    # 4. è¿æ¥æœåŠ¡å™¨å¹¶å…¥åº“ (Client/Server æ¨¡å¼)
    print(f"ğŸ’¾ Sending vectors to Chroma Server...")
    
    client = chromadb.HttpClient(
        host=os.getenv("CHROMA_SERVER_HOST", "localhost"),
        port=os.getenv("CHROMA_SERVER_PORT", "8000")
    )

    vector_store = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        client=client,
        collection_name="enterprise_docs"
    )
    
    print("âœ… Ingestion complete! The Brain (Server) is ready.")

if __name__ == "__main__":
    ingest_docs()
